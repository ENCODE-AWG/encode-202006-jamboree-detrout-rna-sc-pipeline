{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "norwegian-racing",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-assurance",
   "metadata": {},
   "source": [
    "We discussed what to do witht the pipeline configuration files, and it was suggested I submit them as attachments.\n",
    "\n",
    "They attachments may also need to be added to Analysis objects that Jennifer added.\n",
    "\n",
    "The DCC doesn't support yaml, so I'll probably need to submit them as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import os\n",
    "import sys\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "EC = str(Path(\"~/proj/encoded_client\").expanduser())\n",
    "if EC not in sys.path:\n",
    "    sys.path.append(EC)\n",
    "\n",
    "from encoded_client.encoded import ENCODED, DCCValidator, Document, HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_configs = []\n",
    "production = Path(\"production\")\n",
    "for lab in production.iterdir():\n",
    "    for library in lab.iterdir():\n",
    "        if library.is_dir():\n",
    "            library_id = library.name\n",
    "            library_configs.append({\n",
    "                \"uuid\": None,\n",
    "                \"local_filename\": library / \"config.yaml\",\n",
    "                \"remote_filename\": str(library / \"config.yaml.txt\"),\n",
    "                \"mime_type\": \"text/plain\",\n",
    "                \"document type\": \"workflow metadata\",\n",
    "                \"md5sum\": None,\n",
    "                \"library_id\": library_id\n",
    "            })\n",
    "library_configs = pandas.DataFrame(library_configs)\n",
    "print(\"Total\", library_configs.shape[0])\n",
    "library_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#server = ENCODED(\"test.encodedcc.org\")\n",
    "server = ENCODED(\"www.encodeproject.org\")\n",
    "validator = DCCValidator(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_by_library_id(server, library_id):\n",
    "    result = server.search_jsonld(searchTerm=library_id)\n",
    "    for experiment_row in result[\"@graph\"]:\n",
    "        if 'Experiment' in experiment_row[\"@type\"]:\n",
    "            return server.get_json(experiment_row[\"@id\"])\n",
    "\n",
    "def get_analysis_by_library_id(server, library_id):\n",
    "    experiment = get_experiment_by_library_id(server, library_id)\n",
    "    if experiment is None:\n",
    "        return\n",
    "    \n",
    "    default_analysis = experiment.get(\"default_analysis\")\n",
    "    if default_analysis is None: \n",
    "        return\n",
    "    \n",
    "    for analysis in experiment[\"analyses\"]:\n",
    "        if analysis[\"@id\"] == default_analysis:\n",
    "            return analysis\n",
    "\n",
    "get_analysis_by_library_id(server, \"ENCLB280ZGL\")[\"@id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posted_documents(server):\n",
    "    posted_documents = []\n",
    "    query = \"/search/?searchTerm=@Documents&lab.title=Barbara%20Wold,%20Caltech\"\n",
    "    graph = server.get_json(query)\n",
    "    for row in graph[\"@graph\"]:\n",
    "        attachment = row[\"attachment\"]\n",
    "        posted_documents.append({\n",
    "            \"date_created\": datetime.strptime(row[\"date_created\"], \"%Y-%m-%dT%H:%M:%S.%f%z\"),\n",
    "            \"@id\": row[\"@id\"],\n",
    "            \"description\": row[\"description\"], \n",
    "            \"document_type\": row[\"document_type\"], \n",
    "            \"mime_type\": attachment[\"type\"], \n",
    "            \"remote_filename\": attachment[\"download\"],\n",
    "            \"href\": attachment[\"href\"]\n",
    "        })\n",
    "    posted_documents = pandas.DataFrame(posted_documents)\n",
    "    return posted_documents\n",
    "\n",
    "posted_documents = get_posted_documents(server)\n",
    "posted_documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "#posted_documents.set_index(\"remote_filename\").loc['production/stanford/ENCLB527WWJ/config.yaml.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_from_posted(posted, filename):\n",
    "    escaped = quote_plus(filename)\n",
    "    candidates = posted[posted[\"remote_filename\"] == escaped]\n",
    "    if candidates.shape[0] == 0:\n",
    "        # no matches\n",
    "        return\n",
    "    elif isinstance(candidates, pandas.DataFrame):\n",
    "        return candidates.loc[candidates.first_valid_index()]\n",
    "    elif isinstance(candidates, pandas.Series):\n",
    "        return candidates\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected internal type {}\".format(type(candidates)))\n",
    "    \n",
    "print(get_document_from_posted(posted_documents, 'production/stanford/ENCLB527WWJ/config.yaml.txt'))\n",
    "print(get_document_from_posted(posted_documents, \"hope_not_real.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_document_from_posted(posted_documents, 'production/stanford_heart_20220621/ENCLB138XBO/config.yaml'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-positive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_document(server, row, library_configs, dry_run=True):\n",
    "    result = {\n",
    "        \"create_document_log\": None,\n",
    "        \"library_id\": None,\n",
    "        \"document_id\": None,\n",
    "        \"analysis_id\": None,\n",
    "        \"filename\": None\n",
    "    }\n",
    "\n",
    "    library_configs = library_configs.set_index(\"remote_filename\")\n",
    "    workflow_doc = Document(\n",
    "        row.local_filename, \n",
    "        \"workflow metadata\", \n",
    "        \"Configuration file for scRNA-seq pipeline\",\n",
    "        filename=row.remote_filename,\n",
    "        server=server,\n",
    "    )\n",
    "    result[\"filename\"] = workflow_doc.filename\n",
    "    \n",
    "    workflow_remote_filename = workflow_doc.filename\n",
    "    library_id = library_configs.loc[workflow_remote_filename][\"library_id\"]\n",
    "    \n",
    "    # try to block double escaping\n",
    "    assert \"%\" not in workflow_remote_filename\n",
    "    posted = get_posted_documents(server)\n",
    "    posted_document = get_document_from_posted(posted, workflow_remote_filename)\n",
    "    \n",
    "    if posted_document is None:\n",
    "        if not dry_run:\n",
    "            result[\"create_document_log\"] = workflow_doc.create_if_needed(server, workflow_doc.uuid, validator)\n",
    "            if result[\"create_document_log\"][\"status\"] == \"success\":\n",
    "                workflow_id = result[\"create_document_log\"][\"@graph\"][0][\"@id\"]\n",
    "            else:\n",
    "                workflow_id = None\n",
    "        else:\n",
    "            workflow_id = \"would create\"\n",
    "    else:\n",
    "        workflow_id = posted_document[\"@id\"]\n",
    "        \n",
    "    # 2) attach document to analysis object    \n",
    "    assert workflow_id is not None\n",
    "    assert library_id is not None\n",
    "    result[\"library_id\"] = library_id\n",
    "    result[\"document_id\"] = workflow_id\n",
    "    \n",
    "    analysis = get_analysis_by_library_id(server, library_id)\n",
    "    if workflow_id not in analysis[\"documents\"]:\n",
    "        #print(\"adding {} to {}\".format(workflow_id, analysis[\"@id\"]))\n",
    "        #documents = analysis[\"documents\"]\n",
    "        #documents.append(workflow_id)\n",
    "        #result = server.patch_json(analysis[\"@id\"], {\"documents\": documents})\n",
    "        #responses.append(result)\n",
    "        result[\"analysis_id\"] = analysis[\"@id\"]\n",
    "        \n",
    "    return result\n",
    "\n",
    "result = submit_document(server, library_configs.loc[556], library_configs, dry_run=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, row in library_configs.iterrows():\n",
    "    results.append(submit_document(server, row, library_configs, dry_run=True))\n",
    "#    if i > 5:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "posted_results = pandas.DataFrame(results)\n",
    "posted_results[[\"library_id\", \"document_id\", \"analysis_id\", \"filename\"]].to_csv(\n",
    "    \"document_analysis_{}.tsv\".format(server.server),\n",
    "    sep=\"\\t\",\n",
    "    index=False\n",
    ")\n",
    "posted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_configs = library_configs[library_configs[\"local_filename\"].apply(lambda lib: Path(lib).parts[1] in (\"stanford_heart_20220810\",))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    latest_results = []\n",
    "    for i, row in latest_configs.iterrows():\n",
    "        latest_results.append(submit_document(server, row, library_configs, dry_run=True))\n",
    "    #    if i > 5:\n",
    "    #        break\n",
    "\n",
    "    latest_results = pandas.DataFrame(latest_results)\n",
    "    target_name = Path(\"document_analysis_{}_20220810.tsv\".format(server.server))\n",
    "    if not target_name.exists():\n",
    "        latest_results[[\"library_id\", \"document_id\", \"analysis_id\", \"filename\"]].to_csv(\n",
    "            target_name,\n",
    "            sep=\"\\t\",\n",
    "            index=False\n",
    "        )\n",
    "    latest_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-vessel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "liz_configs = library_configs[library_configs[\"local_filename\"].apply(lambda lib: Path(lib).parts[1] in (\"liz_reprocess\",))]\n",
    "liz_configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    liz_results = []\n",
    "    for i, row in liz_configs.iterrows():\n",
    "        liz_results.append(submit_document(server, row, liz_configs, dry_run=True))\n",
    "\n",
    "    liz_results = pandas.DataFrame(liz_results)\n",
    "    target_name = Path(\"document_analysis_{}_liz_resubmit.tsv\".format(server.server))\n",
    "    if not target_name.exists():\n",
    "        liz_results[[\"library_id\", \"document_id\", \"analysis_id\", \"filename\"]].to_csv(\n",
    "            target_name,\n",
    "            sep=\"\\t\",\n",
    "            index=False\n",
    "        )\n",
    "    print(liz_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = pandas.DataFrame([[\"ENCSR398YBK\", \"ENCLB398IAZ\", \"barbara-wold:ENCSR398YBK_analysis\"],\n",
    "[\"ENCSR231FNL\", \"ENCLB398IAZ\", \"barbara-wold:ENCSR231FNL_analysis\"],\n",
    "[\"ENCSR176WWW\", \"ENCLB872TNB\", \"barbara-wold:ENCSR176WWW_analysis\"],\n",
    "[\"ENCSR980OCK\", \"ENCSR980OCK\", \"barbara-wold:ENCSR980OCK_analysis\"],\n",
    "[\"ENCSR814LMX\", \"ENCLB366ZFV\", \"barbara-wold:ENCSR814LMX_analysis\"],\n",
    "[\"ENCSR067BOK\", \"ENCLB849AUZ\", \"barbara-wold:ENCSR067BOK_analysis\"]], columns=[\"experiment_id\", \"library_id\", \"alias\"])\n",
    "\n",
    "analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_docs_query = \"https://www.encodeproject.org/report/?type=Analysis&files.assay_term_name=single-cell+RNA+sequencing+assay&documents!=*&pipelines=%2Fpipelines%2FENCPL257SYI%2F&field=%40id&field=status&field=pipeline_award_rfas&field=assembly&field=genome_annotation&field=datasets\"\n",
    "\n",
    "experiments_missing_docs = []\n",
    "for row in server.get_json(missing_docs_query)[\"@graph\"]:\n",
    "    experiment_id = row[\"datasets\"][0]\n",
    "    experiment = server.get_json(experiment_id)\n",
    "    for replicate in experiment[\"replicates\"]:\n",
    "        library = replicate[\"library\"]\n",
    "        experiments_missing_docs.append({\n",
    "            \"experiment\": experiment[\"accession\"],\n",
    "            \"library\": library[\"accession\"],\n",
    "            \"analyses\": row[\"@id\"],\n",
    "            \"date_created\": experiment[\"date_created\"],\n",
    "            \"summary\": experiment[\"simple_biosample_summary\"],\n",
    "            \n",
    "        })\n",
    "\n",
    "experiments_missing_docs = pandas.DataFrame(experiments_missing_docs)\n",
    "experiments_missing_docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_missing_docs = set(experiments_missing_docs[\"library\"].to_list())\n",
    "library_configs[library_configs[\"library_id\"].isin(libraries_missing_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-auckland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-oxford",
   "metadata": {},
   "source": [
    "# Sept 22 heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_sept22_configs = library_configs[library_configs[\"local_filename\"].apply(lambda lib: Path(lib).parts[1] in (\"stanford_heart_20220822\",))]\n",
    "stanford_sept22_configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    stanford_sept22_results = []\n",
    "    for i, row in stanford_sept22_configs.iterrows():\n",
    "        stanford_sept22_results.append(submit_document(server, row, stanford_sept22_configs, dry_run=True))\n",
    "\n",
    "    stanford_sept22_results = pandas.DataFrame(stanford_sept22_results)\n",
    "    target_name = Path(\"document_analysis_{}_stanford_20220822.tsv\".format(server.server))\n",
    "    if not target_name.exists():\n",
    "        stanford_sept22_results[[\"library_id\", \"document_id\", \"analysis_id\", \"filename\"]].to_csv(\n",
    "            target_name,\n",
    "            sep=\"\\t\",\n",
    "            index=False\n",
    "        )\n",
    "    print(stanford_sept22_results.head())\n",
    "    print(stanford_sept22_results.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
