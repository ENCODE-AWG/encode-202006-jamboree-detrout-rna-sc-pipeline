{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "injured-strip",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-tactics",
   "metadata": {},
   "source": [
    "How much does what is included in the annotation set matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ethical-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import scipy\n",
    "import anndata\n",
    "import pandas\n",
    "import scanpy\n",
    "import numpy\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot, cm\n",
    "import sys\n",
    "import pysam\n",
    "from collections import Counter\n",
    "\n",
    "import upsetplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "violent-action",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/woldlab/loxcyc/home/diane/proj/encode-202006-jamboree-detrout-rna-sc-pipeline/lung/ENCSR966DDY_16f_nuc'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "breathing-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path(\"../..\").absolute()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "from common import compute_spearman_anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "about-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "v29_genome_dir = Path(\"~/proj/genome/\").expanduser()\n",
    "v29_store = pandas.HDFStore(v29_genome_dir / \"GRCh38-V29-male\" / \"GRCh38-V29-male.h5\")\n",
    "v29_gtf = v29_store.select('/gtf', where='type == gene', columns=['gene_id', 'gene_name', 'gene_type'])\n",
    "v29_store.close()\n",
    "\n",
    "v29_gene_base_to_id = {}\n",
    "v29_gene_id_to_name = {}\n",
    "v29_gene_id_to_type = {}\n",
    "for i, row in v29_gtf.iterrows():\n",
    "    v29_gene_base_to_id[row.gene_id.split('.')[0]] = row.gene_id\n",
    "    v29_gene_id_to_name[row.gene_id] = row.gene_name\n",
    "    v29_gene_id_to_type[row.gene_id] = row.gene_type\n",
    "\n",
    "def calculate_v29_gene_base(gene_id):\n",
    "    gene_base = gene_id.split('.')[0]\n",
    "    if gene_id.endswith(\"_PAR_Y\"):\n",
    "        gene_base += \"_PAR_Y\"\n",
    "    return gene_base\n",
    "v29_gtf['gene_base'] = v29_gtf['gene_id'].apply(calculate_v29_gene_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "diverse-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "v32m_genome_dir = Path(\"~/proj/encode-202006-jamboree-detrout-rna-sc-pipeline/genome/\").expanduser()\n",
    "v32m_store = pandas.HDFStore(v32m_genome_dir / \"GRCh38-arc2.0-2.7.8a\" / \"GRCh38-arc2.0-2.7.8a.h5\")\n",
    "v32m_gtf = v32m_store.select('/gtf', where='type == gene', columns=['gene_id', 'gene_name', 'gene_type'])\n",
    "v32m_store.close()\n",
    "\n",
    "v32m_gtf.columns = ['gene_base', 'gene_name', 'gene_type']\n",
    "v32m_gtf['gene_id'] = v32m_gtf['gene_base'].apply(lambda x: v29_gene_base_to_id.get(x, x))\n",
    "\n",
    "v32m_gene_id_to_name = {}\n",
    "v32m_gene_id_to_type = {}\n",
    "for i, row in v32m_gtf.iterrows():\n",
    "    v32m_gene_id_to_name[row.gene_id] = row.gene_name\n",
    "    v32m_gene_id_to_type[row.gene_id] = row.gene_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-density",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documentary-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanpy_load_solo278a_mtx(analysis_dir, quantification=\"Gene\", mode=\"filtered\"):\n",
    "    assert mode in [\"filtered\", \"raw\"], \"STAR Solo only produces raw or filtered files\"\n",
    "    assert quantification in [\"Gene\", \"GeneFull\", \"SJ\"]\n",
    "\n",
    "    analysis_dir = Path(analysis_dir)\n",
    "    feature_name = \"features.tsv\"\n",
    "    \n",
    "    solo_dir = analysis_dir / \"Solo.out\" / quantification / mode\n",
    "    solo = scanpy.read_mtx(solo_dir / \"matrix.mtx\").T\n",
    "    solo_vars = pandas.read_csv(\n",
    "        solo_dir / feature_name, header=None, sep=\"\\t\"\n",
    "    ).values.T\n",
    "    solo_obs = pandas.read_csv(\n",
    "        solo_dir / \"barcodes.tsv\", header=None, sep=\"\\t\"\n",
    "    ).values.T\n",
    "    solo.obs_names = solo_obs[0]\n",
    "    solo.var_names = solo_vars[0]\n",
    "\n",
    "    solo.obs[\"counts\"] = solo.X.sum(axis=1)\n",
    "    solo.obs[\"ngenes\"] = numpy.array((solo.X > 0).sum(axis=1))\n",
    "\n",
    "    return solo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-concept",
   "metadata": {},
   "source": [
    "I tried to do an analysis using the the different modes of soloMultiMappers but they seemed too similar.\n",
    "Then I computed the md5sum of the matrix files... and yeah the argument didn't seem to do anything.\n",
    "\n",
    "<table>\n",
    "<tr><td>ffb6d23ee397674a310d93039e4111a7</td><td>fullsolo_2.7.9a_2021-06-25/Solo.out/GeneFull/filtered/matrix.mtx</td></tr>\n",
    "<tr><td>ffb6d23ee397674a310d93039e4111a7</td><td>fullsolo_em_2.7.9a_2021-06-25/Solo.out/GeneFull/filtered/matrix.mtx</td></tr>\n",
    "<tr><td>ffb6d23ee397674a310d93039e4111a7</td><td>fullsolo_rescue_2.7.9a_2021-06-25/Solo.out/GeneFull/filtered/matrix.mtx</td></tr>\n",
    "<tr><td>00dd2450e656ceaffe533c4558e16227</td><td>minimalsolo_2.7.9a_2021-06-25/Solo.out/GeneFull/filtered/matrix.mtx</td></tr>\n",
    "<tr><td>00dd2450e656ceaffe533c4558e16227</td><td>minimalsolo_em_2.7.9a_2021-06-25/Solo.out/GeneFull/filtered/matrix.mtx</td></tr>\n",
    "<tr><td>00dd2450e656ceaffe533c4558e16227</td><td>minimalsolo_rescue_2.7.9a_2021-06-25/Solo.out/GeneFull/filtered/matrix.mtx</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-checkout",
   "metadata": {},
   "source": [
    "I also learned that there's some gene base ids that have two version varients. (One example)\n",
    "<table>\n",
    "<tr><td>gene_id \t</td><td>gene_name \t</td><td>gene_type</td></tr>\n",
    "<tr><td>ENSG00000169084.13 \t</td><td>DHRSX \t</td><td>protein_coding</td></tr>\n",
    "    <tr><td>ENSG00000169084.13_PAR_Y \t</td><td>DHRSX \t</td><td>protein_coding</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-pattern",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "latter-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_roots = {\n",
    "    'tenx solo uniq': Path(\"starsolo_2.7.9a_2021-06-25_encode-forward+cr\"),\n",
    "    'encode full solo uniq': Path(\"fullsolo_2.7.9a_2021-06-25\"),\n",
    "    #'encode full solo rescue': Path(\"fullsolo_rescue_2.7.9a_2021-06-25\"),\n",
    "    #'encode full solo em': Path(\"fullsolo_em_2.7.9a_2021-06-25\"),\n",
    "    'encode minimal solo uniq': Path(\"minimalsolo_2.7.9a_2021-06-25\"),\n",
    "    #'encode minimal solo rescue': Path(\"minimalsolo_rescue_2.7.9a_2021-06-25\"),\n",
    "    #'encode minimal solo em': Path(\"minimalsolo_em_2.7.9a_2021-06-25\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chubby-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tenx solo uniq\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'starsolo_2.7.9a_2021-06-25_encode-forward+cr/Solo.out/GeneFull/filtered/matrix.mtx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c86a1878b13b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgorithm_roots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0malgorithm_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscanpy_load_solo278a_mtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm_roots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GeneFull\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filtered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-cfcdb9bf7070>\u001b[0m in \u001b[0;36mscanpy_load_solo278a_mtx\u001b[0;34m(analysis_dir, quantification, mode)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msolo_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"Solo.out\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mquantification\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscanpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolo_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"matrix.mtx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     solo_vars = pandas.read_csv(\n\u001b[1;32m     11\u001b[0m         \u001b[0msolo_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/anndata/_io/read.py\u001b[0m in \u001b[0;36mread_mtx\u001b[0;34m(filename, dtype)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;31m# could be rewritten accounting for dtype to be more performant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/io/mmio.py\u001b[0m in \u001b[0;36mmmread\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/io/mmio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/io/mmio.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(filespec, mode)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# open for writing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'starsolo_2.7.9a_2021-06-25_encode-forward+cr/Solo.out/GeneFull/filtered/matrix.mtx'"
     ]
    }
   ],
   "source": [
    "algorithm_filtered = {}\n",
    "for algorithm in algorithm_roots:\n",
    "    print(\"loading {}\".format(algorithm))\n",
    "    algorithm_filtered[algorithm] = scanpy_load_solo278a_mtx(algorithm_roots[algorithm], \"GeneFull\", \"filtered\")\n",
    "    print(algorithm, algorithm_filtered[algorithm].shape, algorithm_filtered[algorithm].X.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-setting",
   "metadata": {},
   "source": [
    "# Add (faked) version to 10x annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_filtered['tenx solo uniq'].var_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_filtered['tenx solo uniq'].var_names = v32m_gtf.set_index('gene_base').reindex(algorithm_filtered['tenx solo uniq'].var_names.to_list())['gene_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_filtered['tenx solo uniq'].var_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-ranch",
   "metadata": {},
   "source": [
    "# Remove version from ENCODE annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm_filtered['encode minimal solo uniq'].var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for algorithm in algorithm_filtered:\n",
    "#    if algorithm != 'tenx solo uniq':\n",
    "#        algorithm_filtered[algorithm].var_names = [x.split('.')[0] for x in algorithm_filtered[algorithm].var_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm_filtered['encode minimal solo uniq'].var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-therapist",
   "metadata": {},
   "source": [
    "# Cell barcodes in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_cell_barcodes = {}\n",
    "for algorithm in algorithm_filtered:\n",
    "    algorithm_cell_barcodes[algorithm] = algorithm_filtered[algorithm].obs_names\n",
    "\n",
    "common_cell_barcode_set = upsetplot.from_contents(algorithm_cell_barcodes)\n",
    "f = pyplot.figure()\n",
    "f.suptitle(\"Cell Barcodes in Common\")\n",
    "_ = upsetplot.plot(common_cell_barcode_set, fig=f, show_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_gene_base_ids = {}\n",
    "for algorithm in algorithm_filtered:\n",
    "    algorithm_gene_base_ids[algorithm] = set(algorithm_filtered[algorithm].var_names)\n",
    "\n",
    "common_gene_base_contents = upsetplot.from_contents(algorithm_gene_base_ids)\n",
    "\n",
    "# tenx is using gencode.v32.primary_assembly.annotation.gtf.filtered\n",
    "f = pyplot.figure()\n",
    "f.suptitle(\"Base gene id's in common\")\n",
    "_ = upsetplot.plot(common_gene_base_contents, fig=f, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_encode_minimal = common_gene_base_contents.loc[True,True,False]['id'].values\n",
    "\n",
    "changed_between_versions = []\n",
    "for gene_base in not_in_encode_minimal:\n",
    "    changed_between_versions.append({\n",
    "        'gene_base': gene_base,\n",
    "        'v29_type': v29_gene_id_to_type[gene_base],\n",
    "        'v32_type': v32m_gene_id_to_type[gene_base],\n",
    "    })\n",
    "    \n",
    "changed_between_versions = pandas.DataFrame(changed_between_versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_between_versions[changed_between_versions['v29_type'] != changed_between_versions['v32_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_between_versions[changed_between_versions['v29_type'] != changed_between_versions['v32_type']]['v32_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cell_barcode_set = None\n",
    "for algorithm in algorithm_filtered:\n",
    "    if common_cell_barcode_set is None:\n",
    "        common_cell_barcode_set = set(algorithm_filtered[algorithm].obs_names)\n",
    "    else:\n",
    "        common_cell_barcode_set = common_cell_barcode_set.intersection(algorithm_filtered[algorithm].obs_names)\n",
    "\n",
    "print('common_cell_barcode_set', len(common_cell_barcode_set))\n",
    "common_cell_barcodes = [x for x in algorithm_filtered['encode full solo uniq'].obs_names if x in common_cell_barcode_set]\n",
    "print('common_cell_barcodes', len(common_cell_barcodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_gene_id_set = None\n",
    "for algorithm in algorithm_filtered:\n",
    "    #if algorithm == 'tenx solo uniq':\n",
    "    #    continue\n",
    "    if common_gene_id_set is None:\n",
    "        common_gene_id_set = set(algorithm_filtered[algorithm].var_names)\n",
    "    else:\n",
    "        common_gene_id_set = common_gene_id_set.intersection(algorithm_filtered[algorithm].var_names)\n",
    "\n",
    "print(\"common_gene_id_set\", len(common_gene_id_set), len(set(common_gene_id_set)))\n",
    "common_gene_ids = [x for x in algorithm_filtered['encode full solo uniq'].var_names if x in common_gene_id_set]\n",
    "print(\"common_gene_ids\", len(common_gene_ids), len(set(common_gene_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenx_gene_base = set(algorithm_filtered['tenx solo uniq'].var_names)\n",
    "#v29_common_gene_base = [x.split('.')[0] for x in algorithm_filtered['encode full solo uniq'].var_names if x.split('.')[0] in tenx_gene_base and x in common_gene_ids]\n",
    "#v29_common_gene_ids = [x for x in algorithm_filtered['encode full solo uniq'].var_names if x.split('.')[0] in tenx_gene_base and x in common_gene_ids]\n",
    "#print(len(v29_common_gene_base), v29_common_gene_base[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_common = {}\n",
    "for algorithm in algorithm_filtered:\n",
    "    algorithm_common[algorithm] = algorithm_filtered[algorithm][common_cell_barcodes, common_gene_ids]\n",
    "    print(algorithm, algorithm_common[algorithm].shape, algorithm_common[algorithm].X.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearman_anndata(left, right):\n",
    "    assert left.shape == right.shape, \"Shapes must be the same\"\n",
    "    if isinstance(left, anndata._core.anndata.AnnData):\n",
    "        left = left.to_df().T\n",
    "    if isinstance(right, anndata._core.anndata.AnnData):\n",
    "        right = right.to_df().T\n",
    "\n",
    "    #print(left.shape[0])\n",
    "    #print(left[0].shape)\n",
    "    #print(right[0].shape)\n",
    "    cors=[]\n",
    "    for c in left.columns:\n",
    "        cors.append(scipy.stats.spearmanr(left[c], right[c])[0])\n",
    "    cors = pandas.Series(cors, index=left.columns)\n",
    "    #[~numpy.isnan(cors)]\n",
    "    return cors\n",
    "\n",
    "\n",
    "def compute_correlations(table):\n",
    "    programs = list(table.keys())\n",
    "    correlations = {}\n",
    "    dense = {}\n",
    "    for name_x in programs:\n",
    "        dense[name_x] = table[name_x].to_df().T\n",
    "\n",
    "    for name_x in programs:\n",
    "        for name_y in programs[programs.index(name_x):]:\n",
    "            print(\"Processing {} {}\".format(name_x, name_y))\n",
    "            cs_cors = compute_spearman_anndata(dense[name_x], dense[name_y])\n",
    "            correlations.setdefault(name_x, {})[name_y] = cs_cors\n",
    "    return correlations\n",
    "\n",
    "algorithm_correlations = compute_correlations(algorithm_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cell_correlation_histogram(table, title=None, bins=50, programs=None):\n",
    "    if programs is None:\n",
    "        programs = list(table.keys())\n",
    "    cell_hists = {}\n",
    "    f = pyplot.figure(figsize=(10, 10))\n",
    "    if title is not None:\n",
    "        f.suptitle(title.format(metric=metric))\n",
    "    plot_size = len(programs)-1\n",
    "\n",
    "    axes = f.subplots(plot_size, plot_size, sharex=True, sharey=True)\n",
    "    if plot_size == 1:\n",
    "        axes = numpy.array([[axes]])\n",
    "    for x, name_x in enumerate(programs):\n",
    "        for y, name_y in enumerate(programs[programs.index(name_x)+1:]):\n",
    "            #plot_index = plot_size * (y+x) + x + 1\n",
    "            #ax = f.add_subplot(plot_size, plot_size, plot_index)\n",
    "            ax = axes[y+x, x]\n",
    "            if x == 0:\n",
    "                ax.set_ylabel(name_y)\n",
    "\n",
    "            spearman = numpy.array(table[name_x][name_y])\n",
    "            spearman = spearman[~numpy.isnan(spearman)]\n",
    "            count = len(spearman)\n",
    "            median = numpy.median(spearman)\n",
    "            mean = numpy.mean(spearman)\n",
    "            cell_hists.setdefault(name_x, {})[name_y] = ax.hist(spearman, bins=bins, density=True)\n",
    "            ax.annotate(f'Mean {mean:0.2}\\nMedian {median:0.2}\\nCount {count}', xy=(0.1, 0.6), xycoords='axes fraction')\n",
    "    for y in range(plot_size):\n",
    "        axes[0, y].set_title(programs[y])\n",
    "        axes[plot_size-1, y].set_xlabel(programs[y])\n",
    "    #f.tight_layout()\n",
    "    \n",
    "plot_cell_correlation_histogram(algorithm_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algorithm_sums(table, title=None, programs=None):\n",
    "    if programs is None:\n",
    "        programs = list(table.keys())\n",
    "    scatter = {}\n",
    "    f = pyplot.figure(figsize=(10, 10))\n",
    "    if title is not None:\n",
    "        f.suptitle(title.format(metric=metric))\n",
    "    plot_size = len(programs)-1\n",
    "\n",
    "    axes = f.subplots(plot_size, plot_size, sharex=True, sharey=True)\n",
    "    if plot_size == 1:\n",
    "        axes = numpy.array([[axes]])\n",
    "    for x, name_x in enumerate(programs):\n",
    "        for y, name_y in enumerate(programs[programs.index(name_x)+1:]):\n",
    "            #plot_index = plot_size * (y+x) + x + 1\n",
    "            #ax = f.add_subplot(plot_size, plot_size, plot_index)\n",
    "            ax = axes[y+x, x]\n",
    "            if x == 0:\n",
    "                ax.set_ylabel(name_y)\n",
    "\n",
    "            scatter.setdefault(name_x, {})[name_y] = ax.scatter(\n",
    "                numpy.asarray(table[name_x].X.sum(axis=1).T)[0], \n",
    "                numpy.asarray(table[name_y].X.sum(axis=1).T)[0],\n",
    "                s=0.5\n",
    "            )\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "    for y in range(plot_size):\n",
    "        axes[0, y].set_title(programs[y])\n",
    "        axes[plot_size-1, y].set_xlabel(programs[y])\n",
    "    f.suptitle(\"per algorithm sum of genes over all cells\")\n",
    "    #f.tight_layout()\n",
    "    \n",
    "plot_algorithm_sums(algorithm_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-watershed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_dense = {}\n",
    "for algorithm in algorithm_common:\n",
    "    algorithm_dense[algorithm] = algorithm_common[algorithm].to_df().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_scatter(table, correlations, name_x, name_y, cell_id, ax=None):\n",
    "    gridalpha = 0.5\n",
    "    def is_spike(x):\n",
    "        if x.startswith('gSpikein_') or x.startswith('tSpikein_'):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    if ax is None:\n",
    "        f = pyplot.figure()\n",
    "        ax = f.subplots(1,1)\n",
    "    \n",
    "    set1 = cm.get_cmap('Set1').colors\n",
    "    colors = [{True: set1[0], False: set1[1]}[is_spike(x)] for x in table[name_x].index]\n",
    "\n",
    "    ax.plot([-5,10], [-5,10], c=set1[2])\n",
    "    ax.scatter(numpy.log2(table[name_x][cell_id]+0.01), numpy.log2(table[name_y][cell_id]+0.01), color=colors, s=2)\n",
    "    spearman = correlations[name_x][name_y][cell_id]\n",
    "    expressed_in_x = table[name_x][cell_id] > 0\n",
    "    expressed_in_y = table[name_y][cell_id] > 0\n",
    "    count = table[name_x][expressed_in_x & expressed_in_y].shape[0]\n",
    "    ax.set_title(f'id {cell_id}\\nSpearman {spearman:0.4}\\nCount: {count}')\n",
    "    ax.set_xlabel(name_x)\n",
    "    ax.set_ylabel(name_y)\n",
    "    ax.grid(color='dimgrey', linestyle='-', linewidth=0.5, which=\"both\", alpha = gridalpha)\n",
    "\n",
    "def show_scatter_extremes(dense_mat, correlations, name_x, name_y):\n",
    "    scores = correlations[name_x][name_y]\n",
    "    best_cell = scores.idxmax()\n",
    "    worst_cell = scores.idxmin()\n",
    "    # find smallest absolute difference from median and use that as median cell\n",
    "    median = numpy.abs(scores - scores.median())\n",
    "    median_cell = median.idxmin()\n",
    "    \n",
    "    f = pyplot.figure(figsize=(12,4))\n",
    "    #f.suptitle(f'{metric} worst, median and best cells')\n",
    "    axes = f.subplots(1,3, sharex=True, sharey=True)\n",
    "    sc_scatter(dense_mat, correlations, name_x, name_y, worst_cell, ax=axes[0])\n",
    "    sc_scatter(dense_mat, correlations, name_x, name_y, median_cell, ax=axes[1])\n",
    "    sc_scatter(dense_mat, correlations, name_x, name_y, best_cell, ax=axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scatter_extremes(algorithm_dense, algorithm_correlations,'encode full solo uniq', 'encode minimal solo uniq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algorithm_most_expressed(table, correlations, title=None, programs=None):\n",
    "    if programs is None:\n",
    "        programs = list(table.keys())\n",
    "    scatter = {}\n",
    "    f = pyplot.figure(figsize=(10, 10))\n",
    "    if title is not None:\n",
    "        f.suptitle(title.format(metric=metric))\n",
    "    plot_size = len(programs)-1\n",
    "\n",
    "    axes = f.subplots(plot_size, plot_size, sharex=True, sharey=True)\n",
    "    if plot_size == 1:\n",
    "        axes = numpy.array([[axes]])\n",
    "    for x, name_x in enumerate(programs):\n",
    "        for y, name_y in enumerate(programs[programs.index(name_x)+1:]):\n",
    "            #plot_index = plot_size * (y+x) + x + 1\n",
    "            #ax = f.add_subplot(plot_size, plot_size, plot_index)\n",
    "            ax = axes[y+x, x]\n",
    "            if x == 0:\n",
    "                ax.set_ylabel(name_y)\n",
    "\n",
    "            max_cell = algorithm_dense[name_x].sum(axis=0).idxmax()\n",
    "            scatter.setdefault(name_x, {})[name_y] = sc_scatter(table, correlations, name_x, name_y, max_cell, ax=ax)\n",
    "    for y in range(plot_size):\n",
    "        axes[0, y].set_title(programs[y])\n",
    "        axes[plot_size-1, y].set_xlabel(programs[y])\n",
    "    f.suptitle(\"Compare algorithms with cell with highest expression sum\")\n",
    "    #f.tight_layout()\n",
    "    \n",
    "plot_algorithm_most_expressed(algorithm_dense, algorithm_correlations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-receptor",
   "metadata": {},
   "source": [
    "It seems weird that there's expression in encode minimal, but not in encode full, maybe I have the labels backward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_minimal_uniq_sum = algorithm_dense['encode minimal solo uniq'].sum(axis=1)\n",
    "encode_full_uniq_sum = algorithm_dense['encode full solo uniq'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_minimal_uniq_sum = encode_minimal_uniq_sum > 0\n",
    "not_in_minimal_uniq_sum = encode_minimal_uniq_sum == 0\n",
    "in_full_uniq_sum = encode_full_uniq_sum > 0\n",
    "not_in_full_uniq_sum =(encode_full_uniq_sum == 0)\n",
    "\n",
    "encode_minimal_uniq_sum[in_minimal_uniq_sum & not_in_full_uniq_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "v29_gtf.set_index('gene_id').reindex(encode_minimal_uniq_sum[in_minimal_uniq_sum & not_in_full_uniq_sum].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-liability",
   "metadata": {},
   "source": [
    "# Lets try the scanpy tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-vault",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for algorithm in algorithm_filtered:\n",
    "    print(\"Processing {}\".format(algorithm))\n",
    "    if algorithm == \"tenx solo uniq\":\n",
    "        algorithm_filtered[algorithm].var['gene_name'] = [v32m_gene_id_to_name.get(x, x) for x in  algorithm_filtered[algorithm].var_names]\n",
    "        algorithm_filtered[algorithm].var['gene_type'] = [v32m_gene_id_to_type.get(x, x) for x in  algorithm_filtered[algorithm].var_names]\n",
    "    else:\n",
    "        algorithm_filtered[algorithm].var['gene_name'] = [v29_gene_id_to_name.get(x, x) for x in  algorithm_filtered[algorithm].var_names]\n",
    "        algorithm_filtered[algorithm].var['gene_type'] = [v29_gene_id_to_type.get(x, x) for x in  algorithm_filtered[algorithm].var_names]\n",
    "        \n",
    "    scanpy.pl.highest_expr_genes(algorithm_filtered[algorithm], n_top=20, gene_symbols='gene_name')\n",
    "    scanpy.pp.filter_cells(algorithm_filtered[algorithm], min_genes=200)\n",
    "    scanpy.pp.filter_genes(algorithm_filtered[algorithm], min_cells=3)\n",
    "    algorithm_filtered[algorithm].var['mt'] = algorithm_filtered[algorithm].var['gene_name'].str.startswith(\"MT-\")\n",
    "    scanpy.pp.calculate_qc_metrics(algorithm_filtered[algorithm], qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    scanpy.pl.violin(\n",
    "        algorithm_filtered[algorithm],\n",
    "        ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],\n",
    "        jitter=0.4, multi_panel=True)\n",
    "    scanpy.pl.scatter(algorithm_filtered[algorithm], x='total_counts', y='pct_counts_mt')\n",
    "    scanpy.pl.scatter(algorithm_filtered[algorithm], x='total_counts', y='n_genes_by_counts')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_filtered[algorithm].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-leone",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algorithm_scanpy_filtered = {}\n",
    "algorithm_top_gene_ids = {}\n",
    "algorithm_top_gene_names = {}\n",
    "for algorithm in algorithm_filtered:\n",
    "    print(\"Processing {}\".format(algorithm))\n",
    "    algorithm_scanpy_filtered[algorithm] = algorithm_filtered[algorithm][algorithm_filtered[algorithm].obs.n_genes_by_counts < 2000, :]\n",
    "    algorithm_scanpy_filtered[algorithm] = algorithm_scanpy_filtered[algorithm][algorithm_scanpy_filtered[algorithm].obs.pct_counts_mt < 2.5, :]\n",
    "    \n",
    "    scanpy.pp.normalize_total(algorithm_scanpy_filtered[algorithm], target_sum=30000)\n",
    "    scanpy.pp.log1p(algorithm_scanpy_filtered[algorithm])\n",
    "    scanpy.pp.highly_variable_genes(algorithm_scanpy_filtered[algorithm], min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    scanpy.pl.highly_variable_genes(algorithm_scanpy_filtered[algorithm])\n",
    "    algorithm_scanpy_filtered[algorithm].raw = algorithm_scanpy_filtered[algorithm]\n",
    "    algorithm_scanpy_filtered[algorithm] = algorithm_scanpy_filtered[algorithm][:, algorithm_scanpy_filtered[algorithm].var.highly_variable]\n",
    "   \n",
    "    scanpy.pp.regress_out( algorithm_scanpy_filtered[algorithm], ['total_counts', 'pct_counts_mt'])\n",
    "    scanpy.pp.scale( algorithm_scanpy_filtered[algorithm], max_value=10)\n",
    "    scanpy.tl.pca(algorithm_scanpy_filtered[algorithm], svd_solver='arpack')\n",
    "    scanpy.pl.pca(algorithm_scanpy_filtered[algorithm])\n",
    "\n",
    "    scanpy.pl.pca_variance_ratio(algorithm_scanpy_filtered[algorithm], log=True)\n",
    "    \n",
    "    scanpy.pp.neighbors(algorithm_scanpy_filtered[algorithm], n_neighbors=10, n_pcs=40)\n",
    "    scanpy.tl.umap(algorithm_scanpy_filtered[algorithm])\n",
    "    scanpy.pl.umap(algorithm_scanpy_filtered[algorithm])\n",
    "    \n",
    "    scanpy.tl.louvain(algorithm_scanpy_filtered[algorithm])\n",
    "    scanpy.pl.umap(algorithm_scanpy_filtered[algorithm], color=['louvain'])\n",
    "    \n",
    "    scanpy.tl.rank_genes_groups(algorithm_scanpy_filtered[algorithm], 'louvain', method='t-test')\n",
    "    scanpy.pl.rank_genes_groups(algorithm_scanpy_filtered[algorithm], n_genes=25, sharey=False, gene_symbols='gene_name')\n",
    "    \n",
    "    algorithm_top_gene_ids[algorithm] = pandas.DataFrame(algorithm_scanpy_filtered[algorithm].uns['rank_genes_groups']['names'])    \n",
    "    if algorithm == \"tenx solo uniq\":\n",
    "        algorithm_top_gene_names[algorithm] = algorithm_top_gene_ids[algorithm].applymap(lambda x: v32m_gene_id_to_name.get(x, x))\n",
    "    else:\n",
    "        algorithm_top_gene_names[algorithm] = algorithm_top_gene_ids[algorithm].applymap(lambda x: v29_gene_id_to_name.get(x, x))\n",
    "    print('top gene names')\n",
    "    print(algorithm_top_gene_names[algorithm].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-humor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-academy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutoral_barcode_set = upsetplot.from_contents({\n",
    "    k: algorithm_scanpy_filtered[k].obs_names for k in algorithm_scanpy_filtered\n",
    "})\n",
    "f = pyplot.figure()\n",
    "f.suptitle(\"Cell barcodes in common after scanpy\")\n",
    "_ = upsetplot.plot(tutoral_barcode_set, show_counts=True, fig=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_filtered_gene_base_contents = {}\n",
    "for algorithm in algorithm_scanpy_filtered:\n",
    "    #if algorithm == 'tenx solo uniq':\n",
    "    #    common_filtered_gene_base_contents[algorithm] = {gene_id for gene_id in algorithm_scanpy_filtered[algorithm].var_names}\n",
    "    #else:\n",
    "    #common_filtered_gene_base_contents[algorithm] = {gene_id.split('.')[0] for gene_id in algorithm_scanpy_filtered[algorithm].var_names}\n",
    "    common_filtered_gene_base_contents[algorithm] = set(algorithm_scanpy_filtered[algorithm].var_names)\n",
    "\n",
    "# tenx is using gencode.v32.primary_assembly.annotation.gtf.filtered\n",
    "common_filtered_gene_base_set = upsetplot.from_contents(common_filtered_gene_base_contents)\n",
    "\n",
    "f = pyplot.figure()\n",
    "f.suptitle(\"Gene base ids in common after scanpy\")\n",
    "_ = upsetplot.plot(common_filtered_gene_base_set, show_counts=True, fig=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_filtered_gene_base_set.loc[True, False, True]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-template",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v29_gtf.set_index('gene_id').reindex(common_filtered_gene_base_set.loc[True, False, True]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(left, right, N=20):\n",
    "    confusion = {}\n",
    "    for cluster in left:\n",
    "        for gene in left[cluster].head(N):\n",
    "            confusion.setdefault(gene, {})['left'] = int(cluster)\n",
    "\n",
    "    for cluster in right:\n",
    "        for gene in right[cluster].head(N):\n",
    "            confusion.setdefault(gene, {})['right'] = int(cluster)\n",
    "\n",
    "    last_left = int(left.columns[-1]) + 1\n",
    "    last_right = int(right.columns[-1]) + 1\n",
    "\n",
    "    confusion_matrix = numpy.zeros((last_left+1, last_right+1))\n",
    "\n",
    "    for gene in confusion:\n",
    "        x = confusion[gene].get('left', last_left)\n",
    "        y = confusion[gene].get('right', last_right)\n",
    "        confusion_matrix[x,y] += 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-electricity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algorithm_confusion(table, programs=None, N=20):\n",
    "    if programs is None:\n",
    "        programs = list(table.keys())\n",
    "    confusion = {}\n",
    "    f = pyplot.figure(figsize=(16, 16))\n",
    "    plot_size = len(programs)-1\n",
    "\n",
    "    axes = f.subplots(plot_size, plot_size, sharex=True, sharey=True)\n",
    "    if plot_size == 1:\n",
    "        axes = numpy.array([[axes]])\n",
    "    for x, name_x in enumerate(programs):\n",
    "        for y, name_y in enumerate(programs[programs.index(name_x)+1:]):\n",
    "            #plot_index = plot_size * (y+x) + x + 1\n",
    "            #ax = f.add_subplot(plot_size, plot_size, plot_index)\n",
    "            ax = axes[y+x, x]\n",
    "            cm = build_confusion_matrix(table[name_x], table[name_y], N)\n",
    "            seaborn.heatmap(cm, annot=False, ax=ax)\n",
    "            \n",
    "            if x == 0:\n",
    "                ax.set_ylabel(name_y)\n",
    "    for y in range(plot_size):\n",
    "        axes[0, y].set_title(programs[y])\n",
    "        axes[plot_size-1, y].set_xlabel(programs[y])\n",
    "    f.suptitle(\"Gene name confusion matrix of top {} genes\".format(N))\n",
    "    #f.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_algorithm_confusion(algorithm_top_gene_names, N=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_algorithm_confusion(algorithm_top_gene_names, N=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_algorithm_confusion(algorithm_top_gene_names, N=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-wales",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
